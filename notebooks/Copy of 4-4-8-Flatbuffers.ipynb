{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 4-4-8-Flatbuffers.ipynb","provenance":[{"file_id":"https://github.com/tinyMLx/colabs/blob/master/4-4-8-Flatbuffers.ipynb","timestamp":1614789723405}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"S9eLyYdy9t4I"},"source":["# TensorFlow Lite Flatbuffer Manipulation Example\n","\n","It's possible to read, modify, and write TensorFlow Lite model files from Python. This notebook shows you how.\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tinyMLx/colabs/blob/master/4-4-8-Flatbuffers.ipynb\n","\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tinyMLx/colabs/blob/master/4-4-8-Flatbuffers.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"LN0slo1N-dMT"},"source":["## Software installation\n","\n","The goal is to build a set of Python classes that represent the types stored inside the TFL Flatbuffer files. To do this we need several dependencies:\n"," - The 'flatc' compiler, that converts the model format stored in a text schema to Python accessor classes.\n"," - The text schema itself, describing the model format.\n"," - The Flatbuffer Python library that the accessor classes rely on.\n","\n","The 'flatc' compiler isn't available as a binary download, so we need to build it from source. The version has to match the Flatbuffer Python library on the system, or the resulting generated code won't work, since it will be trying to use a different API. The FB Python library is at version 1.12.0, so we make sure we download the tagged snapshot of the source at that same version from GitHub."]},{"cell_type":"markdown","metadata":{"id":"Gvc8Gv806odl"},"source":["### Install Flatbuffer Python Library\n","\n","We should already have version 1.12.0 by default on this Colab, but use pip to ensure it's installed, and then import it so it's available from Python."]},{"cell_type":"code","metadata":{"id":"v9eegi_vtxW4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614791870667,"user_tz":480,"elapsed":4463,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"f63c6f25-0c03-4851-acbd-8373f980f49d"},"source":["!pip install flatbuffers==1.12.0\n","import flatbuffers"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flatbuffers==1.12.0 in /usr/local/lib/python3.7/dist-packages (1.12)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"njMMlz3L69Re"},"source":["### Build the 'flatc' Compiler\n","\n","We need 'flatc' to generate the Python accessor classes we'll use to read and write the serialized files, and since it's not easily available as a binary, we grab the source code from the right version and build it directly. **This will take a few minutes.**\n","\n","Once the 'flatc' binary has been built, copy it to the `/usr/local/bin` folder so that it's easily accessible as a command."]},{"cell_type":"code","metadata":{"id":"HiM0ZsxO6NuX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614792039470,"user_tz":480,"elapsed":173252,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"55eaa961-45f6-4fd4-e1fd-76b3b60f7082"},"source":["# Build and install the Flatbuffer compiler.\n","%cd /content/\n","!rm -rf flatbuffers*\n","!curl -L \"https://github.com/google/flatbuffers/archive/v1.12.0.zip\" -o flatbuffers.zip\n","!unzip -q flatbuffers.zip\n","!mv flatbuffers-1.12.0 flatbuffers\n","%cd flatbuffers\n","!cmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release\n","!make -j 8\n","!cp flatc /usr/local/bin/"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/content\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   124  100   124    0     0   1050      0 --:--:-- --:--:-- --:--:--  1050\n","100 1463k  100 1463k    0     0  4587k      0 --:--:-- --:--:-- --:--:-- 4587k\n","/content/flatbuffers\n","-- The C compiler identification is GNU 7.5.0\n","-- The CXX compiler identification is GNU 7.5.0\n","-- Check for working C compiler: /usr/bin/cc\n","-- Check for working C compiler: /usr/bin/cc -- works\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Check for working CXX compiler: /usr/bin/c++\n","-- Check for working CXX compiler: /usr/bin/c++ -- works\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Looking for strtof_l\n","-- Looking for strtof_l - found\n","-- Looking for strtoull_l\n","-- Looking for strtoull_l - found\n","-- `tests/monster_test.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `tests/monster_test.fbs`: add generation of binary (.bfbs) schema\n","-- `tests/namespace_test/namespace_test1.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `tests/namespace_test/namespace_test2.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `tests/union_vector/union_vector.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `tests/native_type_test.fbs`: add generation of C++ code with ''\n","-- `tests/arrays_test.fbs`: add generation of C++ code with '--scoped-enums;--gen-compare'\n","-- `tests/arrays_test.fbs`: add generation of binary (.bfbs) schema\n","-- `tests/monster_test.fbs`: add generation of C++ embedded binary schema code with '--no-includes;--gen-compare'\n","-- `tests/monster_extra.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `samples/monster.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n","-- `samples/monster.fbs`: add generation of binary (.bfbs) schema\n","fatal: not a git repository (or any of the parent directories): .git\n","-- Configuring done\n","-- Generating done\n","-- Build files have been written to: /content/flatbuffers\n","\u001b[35m\u001b[1mScanning dependencies of target flatbuffers\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target flathash\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target flatc\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_gen_text.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/reflection.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/util.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object CMakeFiles/flathash.dir/src/flathash.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_parser.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_parser.cpp.o\u001b[0m\n","[  9%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/reflection.cpp.o\u001b[0m\n","[ 10%] \u001b[32m\u001b[1mLinking CXX executable flathash\u001b[0m\n","[ 10%] Built target flathash\n","[ 11%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/util.cpp.o\u001b[0m\n","[ 12%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_js_ts.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o\u001b[0m\n","[ 31%] \u001b[32m\u001b[1mLinking CXX static library libflatbuffers.a\u001b[0m\n","[ 31%] Built target flatbuffers\n","[ 32%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc_main.cpp.o\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/code_generators.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o\u001b[0m\n","[ 37%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o\u001b[0m\n","[ 38%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o\u001b[0m\n","[ 40%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o\u001b[0m\n","[ 41%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o\u001b[0m\n","[ 42%] \u001b[32m\u001b[1mLinking CXX executable flatc\u001b[0m\n","[ 42%] Built target flatc\n","\u001b[35m\u001b[1mScanning dependencies of target generated_code\u001b[0m\n","[ 43%] \u001b[34m\u001b[1mRun generation: 'tests/union_vector/union_vector_generated.h'\u001b[0m\n","[ 44%] \u001b[34m\u001b[1mRun generation: 'samples/monster.bfbs'\u001b[0m\n","[ 45%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test1_generated.h'\u001b[0m\n","[ 47%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test.bfbs'\u001b[0m\n","[ 48%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_generated.h'\u001b[0m\n","[ 49%] \u001b[34m\u001b[1mRun generation: 'tests/native_type_test_generated.h'\u001b[0m\n","[ 50%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test2_generated.h'\u001b[0m\n","[ 51%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test_generated.h'\u001b[0m\n","[ 52%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test.bfbs'\u001b[0m\n","[ 55%] \u001b[34m\u001b[1mRun generation: 'tests/monster_extra_generated.h'\u001b[0m\n","[ 55%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_bfbs_generated.h'\u001b[0m\n","[ 56%] \u001b[34m\u001b[1mRun generation: 'samples/monster_generated.h'\u001b[0m\n","[ 57%] \u001b[34m\u001b[1mAll generated files were updated.\u001b[0m\n","[ 57%] Built target generated_code\n","\u001b[35m\u001b[1mScanning dependencies of target flatsamplebinary\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target flattests\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target flatsamplebfbs\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target flatsampletext\u001b[0m\n","[ 58%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebinary.dir/samples/sample_binary.cpp.o\u001b[0m\n","[ 60%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_text.cpp.o\u001b[0m\n","[ 61%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_parser.cpp.o\u001b[0m\n","[ 62%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_gen_text.cpp.o\u001b[0m\n","[ 63%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_parser.cpp.o\u001b[0m\n","[ 64%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/util.cpp.o\u001b[0m\n","[ 65%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/reflection.cpp.o\u001b[0m\n","[ 67%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_parser.cpp.o\u001b[0m\n","[ 68%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/samples/sample_bfbs.cpp.o\u001b[0m\n","[ 69%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebinary\u001b[0m\n","[ 70%] Built target flatsamplebinary\n","[ 71%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/reflection.cpp.o\u001b[0m\n","[ 72%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/util.cpp.o\u001b[0m\n","[ 74%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n","[ 75%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test.cpp.o\u001b[0m\n","[ 76%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_assert.cpp.o\u001b[0m\n","[ 77%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_builder.cpp.o\u001b[0m\n","[ 78%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/native_type_test_impl.cpp.o\u001b[0m\n","[ 80%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/code_generators.cpp.o\u001b[0m\n","[ 81%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_gen_text.cpp.o\u001b[0m\n","[ 82%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/reflection.cpp.o\u001b[0m\n","[ 83%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/util.cpp.o\u001b[0m\n","[ 84%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/samples/sample_text.cpp.o\u001b[0m\n","[ 85%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebfbs\u001b[0m\n","[ 87%] \u001b[32m\u001b[1mLinking CXX executable flatsampletext\u001b[0m\n","[ 88%] Built target flatsamplebfbs\n","[ 89%] Built target flatsampletext\n","[ 90%] \u001b[32m\u001b[1mLinking CXX executable flattests\u001b[0m\n","[100%] Built target flattests\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D5vlh6BCM9i0"},"source":["### Fetch the Schema\n","\n","The schema is [a text file that describes the layout of the model file format](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_v3.fbs), and it's part of the TensorFlow source code, so we need to fetch the latest version from GitHub."]},{"cell_type":"code","metadata":{"id":"4boI3wM00PnS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614792057357,"user_tz":480,"elapsed":191127,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"ae407f7f-35d6-4447-ef9d-9aa93bd12038"},"source":["%cd /content/\n","!rm -rf tensorflow\n","!git clone --depth 1 https://github.com/tensorflow/tensorflow"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'tensorflow'...\n","remote: Enumerating objects: 23956, done.\u001b[K\n","remote: Counting objects: 100% (23956/23956), done.\u001b[K\n","remote: Compressing objects: 100% (17787/17787), done.\u001b[K\n","remote: Total 23956 (delta 8845), reused 10444 (delta 5601), pack-reused 0\n","Receiving objects: 100% (23956/23956), 57.19 MiB | 11.30 MiB/s, done.\n","Resolving deltas: 100% (8845/8845), done.\n","Checking out files: 100% (24484/24484), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GS1eAfwRNfvG"},"source":["### Generate the Python Accessor Classes\n","\n","The 'flatc' compiler takes the information from the text schema, and creates Python code to read and write the data held inside the serialized Flatbuffer file. The Python classes are written into the `tflite` folder, with names like `Model.py`, and define classes like `ModelT` that contain members that you can use to read or write the contents of the data structures defined by the schema."]},{"cell_type":"code","metadata":{"id":"Xl0_MIlMM6Es","executionInfo":{"status":"ok","timestamp":1614792057357,"user_tz":480,"elapsed":191119,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}}},"source":["!flatc --python --gen-object-api tensorflow/tensorflow/lite/schema/schema_v3.fbs"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8p_5vLNQ_sFF"},"source":["### Model Loading and Saving\n","\n","These are some simple wrapper functions that demonstrate how to load data from a file, turn it into a `ModelT` Python object that can be modified, and then save it out to a new file.\n","\n","We have to do a little bit of hackery with the Python search paths so that the class files we generated from the schema can be imported."]},{"cell_type":"code","metadata":{"id":"acpsc72lvKRW","executionInfo":{"status":"ok","timestamp":1614792057358,"user_tz":480,"elapsed":191117,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}}},"source":["import sys\n","# This hackery allows us to import the Python files we've just generated.\n","sys.path.append(\"/content/tflite/\")\n","import Model\n","\n","def load_model_from_file(model_filename):\n","  with open(model_filename, \"rb\") as file:\n","    buffer_data = file.read()\n","  model_obj = Model.Model.GetRootAsModel(buffer_data, 0)\n","  model = Model.ModelT.InitFromObj(model_obj)\n","  return model\n","\n","def save_model_to_file(model, model_filename):\n","  builder = flatbuffers.Builder(1024)\n","  model_offset = model.Pack(builder)\n","  builder.Finish(model_offset, file_identifier=b'TFL3')\n","  model_data = builder.Output()\n","  with open(model_filename, 'wb') as out_file:\n","    out_file.write(model_data)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vtNYC984AILB"},"source":["## Download an Example Model\n","\n","This pulls down a trained model from the speech commands tutorial that we can use to test the Flatbuffer loading code."]},{"cell_type":"code","metadata":{"id":"56u94mxKsCEM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614798126087,"user_tz":480,"elapsed":1141107,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"a52b907a-b465-4364-82ab-e7f27bdd9d16"},"source":["!curl -O 'https://storage.googleapis.com/download.tensorflow.org/models/tflite/micro/speech_commands_model_2020_04_27.zip'\n","!unzip speech_commands_model_2020_04_27.zip"],"execution_count":25,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 78855  100 78855    0     0  4529k      0 --:--:-- --:--:-- --:--:-- 4529k\n","Archive:  speech_commands_model_2020_04_27.zip\n","replace speech_commands_model/speech_commands_model_float.tflite? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B5SJTcrRBy1X"},"source":["## Load, Modify, and Save a Model\n","\n","The code below loads the float model, applies a small change to the float weights, and saves it out again. In this case we're just changing the contents of the weights, but any of the other properties of the model can be added, removed, or modified, including tensors, ops, and metadata.\n","\n","I've found the easiest way to understand the syntax used and data available is to look at the generated classes in `tflite/` and [the text schema that describes the format](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/schema/schema_v3.fbs)."]},{"cell_type":"code","metadata":{"id":"zex9zZo01lM4","executionInfo":{"status":"ok","timestamp":1614798126088,"user_tz":480,"elapsed":18,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}}},"source":["# Use numpy to make the manipulation of the weight arrays easier.\n","import numpy as np\n","\n","# Load the float model we downloaded as a ModelT object.\n","model = load_model_from_file('/content/speech_commands_model/speech_commands_model_float.tflite')\n","\n","# Loop through all the weights held in the model.\n","for buffer in model.buffers:\n","  # Skip missing or small weight arrays.\n","  if buffer.data is not None and len(buffer.data) > 1024:\n","    # Pull the weight array from the model, and cast it to 32-bit floats since\n","    # we know that's the type for all the weights in this model. In a real\n","    # application we'd need to check the data type from the tensor information\n","    # stored in the model.subgraphs\n","    original_weights = np.frombuffer(buffer.data, dtype=np.float32)\n","\n","    # This is the line where the weights are altered.\n","    # Try replacing it with your own version, for example:\n","    # munged_weights = np.add(original_weights, 0.002)\n","    munged_weights = np.round(original_weights * (1/0.02)) * 0.02\n","\n","    # Write the altered data back into the model.    \n","    buffer.data = munged_weights.tobytes()\n","\n","# Save the ModelT object as a TFL Flatbuffer file.\n","save_model_to_file(model, '/content/speech_commands_model/speech_commands_model_modified.tflite')"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C8EwrywLX9gs"},"source":["## Evaluating the impact of your changes"]},{"cell_type":"markdown","metadata":{"id":"_EAgJJNmZL8T"},"source":["### Setup KWS infrastructure\r\n","\r\n","To evaluate the impact of your changes on the accuracy of the speech model we need to load a test data set and some utility classes to read the files and convert them into the right input form for the network.\r\n","\r\n","**The full dataset is several gigabytes in size, so it may take a few minutes to download.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlrzIA__X9v3","executionInfo":{"status":"ok","timestamp":1614798131329,"user_tz":480,"elapsed":5253,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"f04b35f5-b713-4df1-9527-7005813f6eb0"},"source":["sys.path.append(\"/content/tensorflow/tensorflow/examples/speech_commands/\")\r\n","import input_data\r\n","import models\r\n","\r\n","# A comma-delimited list of the words you want to train for.\r\n","# The options are: yes,no,up,down,left,right,on,off,stop,go\r\n","# All the other words will be used to train an \"unknown\" label and silent\r\n","# audio data with no spoken words will be used to train a \"silence\" label.\r\n","WANTED_WORDS = \"yes,no\"\r\n","\r\n","# The number of steps and learning rates can be specified as comma-separated\r\n","# lists to define the rate at each stage. For example,\r\n","# TRAINING_STEPS=12000,3000 and LEARNING_RATE=0.001,0.0001\r\n","# will run 12,000 training loops in total, with a rate of 0.001 for the first\r\n","# 8,000, and 0.0001 for the final 3,000.\r\n","TRAINING_STEPS = \"12000,3000\"\r\n","LEARNING_RATE = \"0.001,0.0001\"\r\n","\r\n","# Calculate the total number of steps, which is used to identify the checkpoint\r\n","# file name.\r\n","TOTAL_STEPS = str(sum(map(lambda string: int(string), TRAINING_STEPS.split(\",\"))))\r\n","\r\n","# Calculate the percentage of 'silence' and 'unknown' training samples required\r\n","# to ensure that we have equal number of samples for each label.\r\n","number_of_labels = WANTED_WORDS.count(',') + 1\r\n","number_of_total_labels = number_of_labels + 2 # for 'silence' and 'unknown' label\r\n","equal_percentage_of_training_samples = int(100.0/(number_of_total_labels))\r\n","SILENT_PERCENTAGE = equal_percentage_of_training_samples\r\n","UNKNOWN_PERCENTAGE = equal_percentage_of_training_samples\r\n","\r\n","# Constants which are shared during training and inference\r\n","PREPROCESS = 'micro'\r\n","WINDOW_STRIDE =20\r\n","MODEL_ARCHITECTURE = 'tiny_conv' # Other options include: single_fc, conv,\r\n","                      # low_latency_conv, low_latency_svdf, tiny_embedding_conv\r\n","\r\n","# Constants used during training only\r\n","VERBOSITY = 'WARN'\r\n","EVAL_STEP_INTERVAL = '1000'\r\n","SAVE_STEP_INTERVAL = '1000'\r\n","\r\n","# Constants for training directories and filepaths\r\n","DATASET_DIR =  'dataset/'\r\n","LOGS_DIR = 'logs/'\r\n","TRAIN_DIR = 'train/' # for training checkpoints and other files.\r\n","\r\n","SAMPLE_RATE = 16000\r\n","CLIP_DURATION_MS = 1000\r\n","WINDOW_SIZE_MS = 30.0\r\n","FEATURE_BIN_COUNT = 40\r\n","BACKGROUND_FREQUENCY = 0.8\r\n","BACKGROUND_VOLUME_RANGE = 0.1\r\n","TIME_SHIFT_MS = 100.0\r\n","\r\n","DATA_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\r\n","VALIDATION_PERCENTAGE = 10\r\n","TESTING_PERCENTAGE = 10\r\n","\r\n","print('Prepare...')\r\n","model_settings = models.prepare_model_settings(\r\n","    len(input_data.prepare_words_list(WANTED_WORDS.split(','))),\r\n","    SAMPLE_RATE, CLIP_DURATION_MS, WINDOW_SIZE_MS,\r\n","    WINDOW_STRIDE, FEATURE_BIN_COUNT, PREPROCESS)\r\n","\r\n","audio_processor = input_data.AudioProcessor(\r\n","    DATA_URL, DATASET_DIR,\r\n","    SILENT_PERCENTAGE, UNKNOWN_PERCENTAGE,\r\n","    WANTED_WORDS.split(','), VALIDATION_PERCENTAGE,\r\n","    TESTING_PERCENTAGE, model_settings, LOGS_DIR)\r\n","\r\n","print('Done')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Prepare...\n","Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bMsyppDEYaYP","executionInfo":{"status":"ok","timestamp":1614798131330,"user_tz":480,"elapsed":26,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}}},"source":["import tensorflow as tf\r\n","# define our helper function to test the model accuracy\r\n","def test_model_accuracy(model_filename):\r\n","  with tf.compat.v1.Session() as sess:\r\n","    test_data, test_labels = audio_processor.get_data(\r\n","        -1, 0, model_settings, 0, 0,\r\n","        0, 'testing', sess)\r\n","\r\n","  interpreter = tf.lite.Interpreter(model_filename)\r\n","  interpreter.allocate_tensors()\r\n","\r\n","  input_index = interpreter.get_input_details()[0][\"index\"]\r\n","\r\n","  output_index = interpreter.get_output_details()[0][\"index\"]\r\n","  model_output = interpreter.tensor(output_index)\r\n","\r\n","  correct_predictions = 0\r\n","  for i in range(len(test_data)):\r\n","    current_input = test_data[i]\r\n","    current_label = test_labels[i]\r\n","    flattened_input = np.array(current_input.flatten(), dtype=np.float32).reshape(1, 1960)\r\n","    interpreter.set_tensor(input_index, flattened_input)\r\n","    interpreter.invoke()\r\n","    top_prediction = model_output()[0].argmax()\r\n","    if top_prediction == current_label:\r\n","      correct_predictions += 1\r\n","\r\n","  print('Accuracy is %f%% (N=%d)' % ((correct_predictions * 100) / len(test_data), len(test_data)))"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLSPYyKxYoNT"},"source":["### Test your Models\r\n","\r\n","Finally we can test both the standard and your modified models!"]},{"cell_type":"markdown","metadata":{"id":"PDkPbCi_ZYJL"},"source":["**Float model evaluation**\r\n","\r\n","You should see ~91% accuracy with a 67KB model. Note: the exact accuracy may vary by a percent or two as it tests the model on a random sampling of the dataset and therefore sometimes gets particularly lucky or unlucky!"]},{"cell_type":"code","metadata":{"id":"toSX48DGYjqP","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1614798131331,"user_tz":480,"elapsed":23,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}},"outputId":"d1e127a7-0816-437b-949f-bdbe758a0bfa"},"source":["!ls -lah /content/speech_commands_model/speech_commands_model_float.tflite\r\n","test_model_accuracy('/content/speech_commands_model/speech_commands_model_float.tflite')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["-rw-r--r-- 1 root root 67K Apr 27  2020 /content/speech_commands_model/speech_commands_model_float.tflite\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data_1/foreground_volume' with dtype float\n\t [[{{node data_1/foreground_volume}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-6470d1745008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -lah /content/speech_commands_model/speech_commands_model_float.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_model_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/speech_commands_model/speech_commands_model_float.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-53692c04d97c>\u001b[0m in \u001b[0;36mtest_model_accuracy\u001b[0;34m(model_filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m     test_data, test_labels = audio_processor.get_data(\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         0, 'testing', sess)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/tensorflow/tensorflow/examples/speech_commands/input_data.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, how_many, offset, model_settings, background_frequency, background_volume_range, time_shift, mode, sess)\u001b[0m\n\u001b[1;32m    603\u001b[0m       \u001b[0;31m# Run the graph to produce the output audio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m       summary, data_tensor = sess.run(\n\u001b[0;32m--> 605\u001b[0;31m           [self.merged_summaries_, self.output_], feed_dict=input_dict)\n\u001b[0m\u001b[1;32m    606\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_writer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data_1/foreground_volume' with dtype float\n\t [[node data_1/foreground_volume (defined at /content/tensorflow/tensorflow/examples/speech_commands/input_data.py:404) ]]\n\nOriginal stack trace for 'data_1/foreground_volume':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-daf9670bedcd>\", line 67, in <module>\n    TESTING_PERCENTAGE, model_settings, LOGS_DIR)\n  File \"/content/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 203, in __init__\n    self.prepare_processing_graph(model_settings, summaries_dir)\n  File \"/content/tensorflow/tensorflow/examples/speech_commands/input_data.py\", line 404, in prepare_processing_graph\n    tf.float32, [], name='foreground_volume')\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 3179, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6726, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3536, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"markdown","metadata":{"id":"RF3T18DWZe7J"},"source":["**Modified model evaluation**\r\n","\r\n","Test the impact of your changes!"]},{"cell_type":"code","metadata":{"id":"UIfNzw7kZqga","executionInfo":{"status":"aborted","timestamp":1614798131331,"user_tz":480,"elapsed":15,"user":{"displayName":"Ivo Stoyanov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiC55t-WoWYv7LEpYkEljKTRFCqDel11x1tVDCvA=s64","userId":"17127975188804955554"}}},"source":["!ls -lah /content/speech_commands_model/speech_commands_model_modified.tflite\r\n","test_model_accuracy('/content/speech_commands_model/speech_commands_model_modified.tflite')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vzw4-n8HAgtT"},"source":["If you'd like to try more modified models just scroll back up to the **Load, Modify, and Save a Model** section and re-run the modified model generation step and then skip back down to the above to re-test!"]}]}